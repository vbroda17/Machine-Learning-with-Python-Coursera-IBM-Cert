{"cells":[{"cell_type":"markdown","id":"c3876f6f-1e5b-4e1b-a95e-e391bab91796","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n","\n","\n","# Multiple Linear Regression\n","\n","\n","Estimated time needed: **15** minutes\n","    \n","\n","## Objectives\n","\n","After completing this lab, you will be able to:\n","\n","* Use scikit-learn to implement multiple linear regression\n","* Create, train, and test a multiple linear regression model on real data\n"]},{"cell_type":"markdown","id":"18e299f7-308d-41f7-b60f-b2bd42eb6f1b","metadata":{},"outputs":[],"source":["### Import needed packages\n"]},{"cell_type":"markdown","id":"d90f04a6-33f6-4bd5-b585-0d741d39a16b","metadata":{},"outputs":[],"source":["For this lab, you will need to have the following packages:\n"," - NumPy\n"," - Matplotlib\n"," - Pandas\n"," - Scikit-learn\n","\n","To avoid issues importing these libraries, you may execute the following cell to ensure they are available.\n"]},{"cell_type":"code","id":"f11b10cb-2102-4f8a-958a-a887a8a396a6","metadata":{},"outputs":[],"source":["!pip install numpy==2.2.0\n!pip install pandas==2.2.3\n!pip install scikit-learn==1.6.0\n!pip install matplotlib==3.9.3"]},{"cell_type":"markdown","id":"1889a98e-6c51-447c-a296-63507fc4bd8f","metadata":{},"outputs":[],"source":["Now, you can import these libraries for making the code.\n"]},{"cell_type":"code","id":"fcc4e300-385f-4bc6-8015-eb2f782800c6","metadata":{},"outputs":[],"source":["import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline"]},{"cell_type":"markdown","id":"2a78ded4-e2ed-4760-9daa-3f3398cf4a21","metadata":{},"outputs":[],"source":["## Load the data\n","The dataset you will use resides at the following URL. You can use the URL directly with the Pandas library to load the dataset.\n"]},{"cell_type":"code","id":"de4baec4-350f-47e4-8457-7dc27e516e99","metadata":{},"outputs":[],"source":["url= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%202/data/FuelConsumptionCo2.csv\""]},{"cell_type":"markdown","id":"9e4ab62f-ae3e-4a61-8852-e0b7f5bb1eb1","metadata":{},"outputs":[],"source":["\n","## Understand the data\n","\n","### `FuelConsumption.csv`:\n","You will download and use a fuel consumption dataset, **`FuelConsumption.csv`**, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada. [Dataset source](http://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64)\n","\n","- **MODEL YEAR** e.g. 2014\n","- **MAKE** e.g. VOLVO\n","- **MODEL** e.g. S60 AWD\n","- **VEHICLE CLASS** e.g. COMPACT\n","- **ENGINE SIZE** e.g. 3.0\n","- **CYLINDERS** e.g 6\n","- **TRANSMISSION** e.g. AS6\n","- **FUEL TYPE** e.g. Z\n","- **FUEL CONSUMPTION in CITY(L/100 km)** e.g. 13.2\n","- **FUEL CONSUMPTION in HWY (L/100 km)** e.g. 9.5\n","- **FUEL CONSUMPTION COMBINED (L/100 km)** e.g. 11.5\n","- **FUEL CONSUMPTION COMBINED MPG (MPG)** e.g. 25\n","- **CO2 EMISSIONS (g/km)** e.g. 182 \n","\n","Your task will be to create a multiple linear regression model using some of these features to predict CO2 emissions of unobserved cars based on the selected features. \n"]},{"cell_type":"markdown","id":"b035f598-2c27-40a3-86a2-2bf43bfbe2d9","metadata":{},"outputs":[],"source":["<h2 id=\"reading_data\">Load the data</h2>\n"]},{"cell_type":"code","id":"56e4028a-e4ed-4437-9d65-f3fddf0ac6ee","metadata":{},"outputs":[],"source":["df = pd.read_csv(url)\n\n# verify successful load with some randomly selected records\ndf.sample(5)"]},{"cell_type":"markdown","id":"a4858f22-8dbb-4ee1-82d6-cb6f58195db9","metadata":{},"outputs":[],"source":["### Explore and select features\n"]},{"cell_type":"markdown","id":"2fbd39e0-9de6-4dc5-98e5-08780b396c72","metadata":{},"outputs":[],"source":["Let's select a few features to work with that might be predictive of CO2 emissions. \n"]},{"cell_type":"code","id":"4edfbf1e-61a7-4000-bb38-5a6d44ef803f","metadata":{},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","id":"7074f8e7-bc84-4283-b2dd-846140540cbe","metadata":{},"outputs":[],"source":["Notice that some of the variables are not included in the description. This is because they aren't numerical. In practice, you would analyze these features if required to improve the accuracy of your model. In the interest of time, you can omit this step here.  \n","Notice also that MODELYEAR is the same for all cars, so you can drop these variables for this modeling illustration.\n"]},{"cell_type":"code","id":"c33dc5ab-d37b-4b3f-a76d-73542fec05cd","metadata":{},"outputs":[],"source":["# Drop categoricals and any unseless columns\ndf = df.drop(['MODELYEAR', 'MAKE', 'MODEL', 'VEHICLECLASS', 'TRANSMISSION', 'FUELTYPE',],axis=1)"]},{"cell_type":"markdown","id":"af46461e-0c9e-4fdd-99c0-b49aa76f3009","metadata":{},"outputs":[],"source":["Now that you have eliminated some features, take a look at the relationships among the remaining features. \n","\n","Analyzing a correlation matrix that displays the pairwise correlations between all features indicates the level of independence between them. \n","\n","It also indicates how predictive each feature is of the target. \n","\n","You want to eliminate any strong dependencies or correlations between features by selecting the best one from each correlated group.\n"]},{"cell_type":"code","id":"6216ce80-749f-4c8b-b0a6-15d63b7e4969","metadata":{},"outputs":[],"source":["df.corr()"]},{"cell_type":"markdown","id":"8b994a7a-792b-4d4c-a7fe-19df672d6d94","metadata":{},"outputs":[],"source":["Look at the bottom row, which shows the correlation between each variable and the target, 'CO2EMISSIONS'. Each of these shows a fairly high level of correlation, each exceeding 85% in magnitude. Thus all of these features are good candidates. \n","\n","Next, examine the correlations of the distinct pairs. 'ENGINESIZE' and 'CYLINDERS' are highly correlated, but 'ENGINESIZE' is more correlated with the target, so we can drop 'CYLINDERS'. \n","\n","Similarly, each of the four fuel economy variables is highly correlated with each other. Since FUELCONSUMPTION_COMB_MPG is the most correlated with the target, you can drop the others: 'FUELCONSUMPTION_CITY,' 'FUELCONSUMPTION_HWY,' 'FUELCONSUMPTION_COMB.' \n","\n","Notice that FUELCONSUMPTION_COMB and FUELCONSUMPTION_COMB_MPG are not perfectly correlated. They should be, though, because they measure the same property in different units. In practice, you would investigate why this is the case. You might find out that some or all of the data is not useable as is.\n"]},{"cell_type":"code","id":"3f482165-53ff-49d1-ba46-d389744f0508","metadata":{},"outputs":[],"source":["df = df.drop(['CYLINDERS', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB',],axis=1)"]},{"cell_type":"code","id":"9d789ace-416d-4eab-873d-108db45f0beb","metadata":{},"outputs":[],"source":["df.head(9)"]},{"cell_type":"markdown","id":"8c934847-fbcf-4ad7-9196-c839d0b4de32","metadata":{},"outputs":[],"source":["To help with selecting predictive features that are not redundant, consider the following scatter matrix, which shows the scatter plots for each pair of input features. The diagonal of the matrix shows each feature's histogram.\n"]},{"cell_type":"code","id":"f192beb8-2ce1-41a5-9e0e-5c49787419de","metadata":{},"outputs":[],"source":["axes = pd.plotting.scatter_matrix(df, alpha=0.2)\n# need to rotate axis labels so we can read them\nfor ax in axes.flatten():\n    ax.xaxis.label.set_rotation(90)\n    ax.yaxis.label.set_rotation(0)\n    ax.yaxis.label.set_ha('right')\n\nplt.tight_layout()\nplt.gcf().subplots_adjust(wspace=0, hspace=0)\nplt.show()\n    "]},{"cell_type":"markdown","id":"8f14bd7b-d668-4d96-93b6-663ad414cf0a","metadata":{},"outputs":[],"source":["As you can see, the relationship between 'FUELCONSUMPTION_COMB_MPG' and 'CO2EMISSIONS' is non-linear. In addition, you can clearly see three different curves. This suggests exploring the categorical variables to see if they are able to explain these differences. Let's leave this as an exercise for you to explore deeper. Regarding the non-linearity, you will handle this in the next lab. For now, let's just consider through modeling whether fuel economy explains some of the variances in the target as is.\n"]},{"cell_type":"markdown","id":"64a4ccda-473c-46d8-8d4b-4b5546f34045","metadata":{},"outputs":[],"source":["### Extract the input features and labels from the data set\n","Extract the required columns and convert the resulting dataframes to NumPy arrays.\n"]},{"cell_type":"code","id":"1ef8cffb-082c-4940-9e86-83545bf44e11","metadata":{},"outputs":[],"source":["X = df.iloc[:,[0,1]].to_numpy()\ny = df.iloc[:,[2]].to_numpy()"]},{"cell_type":"markdown","id":"361ec875-457b-4277-a0d0-0bd99e91dbe8","metadata":{},"outputs":[],"source":["### Preprocess selected features\n"]},{"cell_type":"markdown","id":"af35a7f1-5bfb-4f14-b890-cd5416ff2850","metadata":{},"outputs":[],"source":["You should standardize your input features so the model doesn't inadvertently favor any feature due to its magnitude.\n","The typical way to do this is to subtract the mean and divide by the standard deviation. Scikit-learn can do this for you.\n"]},{"cell_type":"code","id":"827cd03f-0045-4f58-bac9-8ab652e87bbe","metadata":{},"outputs":[],"source":["from sklearn import preprocessing\n\nstd_scaler = preprocessing.StandardScaler()\nX_std = std_scaler.fit_transform(X)"]},{"cell_type":"markdown","id":"b8c79f48-bf06-41ed-b758-da873fe7c62c","metadata":{},"outputs":[],"source":["In practice, if you want to properly evaluate your model, you should definitely not apply such operations to the entire dataset but to the train and test data separately. There's more to it than that. You'll dive deeper into this and other advanced evaluation pitfalls later in the course.\n"]},{"cell_type":"code","id":"895525f9-1674-40fb-bf56-2fe43f5df495","metadata":{},"outputs":[],"source":["pd.DataFrame(X_std).describe().round(2)"]},{"cell_type":"markdown","id":"68e67315-4054-4da7-89ce-900079e80eb2","metadata":{},"outputs":[],"source":["As you can see, a standardized variable has zero mean and a standard deviation of one.\n"]},{"cell_type":"markdown","id":"0f39995a-ce0f-4614-a1c5-8bafc68eff7c","metadata":{},"outputs":[],"source":["### Create train and test datasets\n","Randomly split your data into train and test sets, using 80% of the dataset for training and reserving the remaining 20% for testing.\n"]},{"cell_type":"code","id":"d48916dc-bbc1-4204-94eb-c2d5549cd85d","metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_std,y,test_size=0.2,random_state=42)"]},{"cell_type":"markdown","id":"e26796cc-e521-4669-97d5-f3f9fc91c83c","metadata":{},"outputs":[],"source":["### Build a multiple linear regression model\n","Multiple and simple linear regression models can be implemented with exactly the same scikit-learn tools.\n"]},{"cell_type":"code","id":"33b36e5a-592f-4e83-b202-58f08ae65c00","metadata":{},"outputs":[],"source":["from sklearn import linear_model\n\n# create a model object\nregressor = linear_model.LinearRegression()\n\n# train the model in the training data\nregressor.fit(X_train, y_train)\n\n# Print the coefficients\ncoef_ =  regressor.coef_\nintercept_ = regressor.intercept_\n\nprint ('Coefficients: ',coef_)\nprint ('Intercept: ',intercept_)\n"]},{"cell_type":"markdown","id":"f34ffe5a-6bd0-45fc-bc8d-1a260c8ce6d7","metadata":{},"outputs":[],"source":["The Coefficients and Intercept parameters define the best-fit hyperplane to the data. Since there are only two variables, hence two parameters, the hyperplane is a plane. But this best-fit plane will look different in the original, unstandardized feature space. \n","\n","You can transform your model's parameters back to the original space prior to standardization as follows. This gives you a proper sense of what they mean in terms of your original input features. Without these adjustments, the model's outputs would be tied to an abstract, transformed space that doesn’t align with the actual independent variables and the real-world problem you’re solving.\n"]},{"cell_type":"code","id":"c7e02313-3210-4c5a-bfb3-6fa58fd1414a","metadata":{},"outputs":[],"source":["# Get the standard scaler's mean and standard deviation parameters\nmeans_ = std_scaler.mean_\nstd_devs_ = np.sqrt(std_scaler.var_)\n\n# The least squares parameters can be calculated relative to the original, unstandardized feature space as:\ncoef_original = coef_ / std_devs_\nintercept_original = intercept_ - np.sum((means_ * coef_) / std_devs_)\n\nprint ('Coefficients: ', coef_original)\nprint ('Intercept: ', intercept_original)\n"]},{"cell_type":"markdown","id":"dbe2d1c3-5593-4f54-a8d2-d45fe219b266","metadata":{},"outputs":[],"source":["You would expect that for the limiting case of zero ENGINESIZE and zero FUELCONSUMPTION_COMB_MPG, the resulting CO2 emissions should also be zero. This is inconsistent with the 'best fit' hyperplane, which has a non-zero intercept of 329 g/km. The answer must be that the target variable does not have a very strong linear relationship to the dependent variables, and/or the data has outliers that are biasing the result. Outliers can be handled in preprocessing, or as you will learn about later in the course, by using regularization techniques. One or more of the variables might have a nonlinear relationship to the target. Or there may still be some colinearity amongst the input variables.\n"]},{"cell_type":"markdown","id":"639fe4ed-4b34-49ae-8c7c-5f44de38e21e","metadata":{},"outputs":[],"source":["### Visualize model outputs\n","You can visualize the goodness-of-fit of the model to the training data by plotting the fitted plane over the data. \n"]},{"cell_type":"code","id":"b9cc40af-d5fa-49ad-9807-5914f04f3d1b","metadata":{},"outputs":[],"source":["#from mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure X1, X2, and y_test have compatible shapes for 3D plotting\nX1 = X_test[:, 0] if X_test.ndim > 1 else X_test\nX2 = X_test[:, 1] if X_test.ndim > 1 else np.zeros_like(X1)\n\n# Create a mesh grid for plotting the regression plane\nx1_surf, x2_surf = np.meshgrid(np.linspace(X1.min(), X1.max(), 100), \n                               np.linspace(X2.min(), X2.max(), 100))\n\ny_surf = intercept_ +  coef_[0,0] * x1_surf  +  coef_[0,1] * x2_surf\n\n# Predict y values using trained regression model to compare with actual y_test for above/below plane colors\ny_pred = regressor.predict(X_test.reshape(-1, 1)) if X_test.ndim == 1 else regressor.predict(X_test)\nabove_plane = y_test >= y_pred\nbelow_plane = y_test < y_pred\nabove_plane = above_plane[:,0]\nbelow_plane = below_plane[:,0]\n\n# Plotting\nfig = plt.figure(figsize=(20, 8))\nax = fig.add_subplot(111, projection='3d')\n\n# Plot the data points above and below the plane in different colors\nax.scatter(X1[above_plane], X2[above_plane], y_test[above_plane],  label=\"Above Plane\",s=70,alpha=.7,ec='k')\nax.scatter(X1[below_plane], X2[below_plane], y_test[below_plane],  label=\"Below Plane\",s=50,alpha=.3,ec='k')\n\n# Plot the regression plane\nax.plot_surface(x1_surf, x2_surf, y_surf, color='k', alpha=0.21,label='plane')\n\n# Set view and labels\nax.view_init(elev=10)\n\nax.legend(fontsize='x-large',loc='upper center')\nax.set_xticks([])\nax.set_yticks([])\nax.set_zticks([])\nax.set_box_aspect(None, zoom=0.75)\nax.set_xlabel('ENGINESIZE', fontsize='xx-large')\nax.set_ylabel('FUELCONSUMPTION', fontsize='xx-large')\nax.set_zlabel('CO2 Emissions', fontsize='xx-large')\nax.set_title('Multiple Linear Regression of CO2 Emissions', fontsize='xx-large')\nplt.tight_layout()\nplt.show()\n"]},{"cell_type":"markdown","id":"8554f02c-0959-4932-9fbd-8296ba31bb6c","metadata":{},"outputs":[],"source":["Instead of making a 3D plot, which is difficult to interpret, you can look at vertical slices of the 3D plot by plotting each variable separately as a best-fit line using the corresponding regression parameters.\n"]},{"cell_type":"code","id":"42da3c95-398a-4cec-ab1c-44f21b1d1f06","metadata":{},"outputs":[],"source":["plt.scatter(X_train[:,0], y_train,  color='blue')\nplt.plot(X_train[:,0], coef_[0,0] * X_train[:,0] + intercept_[0], '-r')\nplt.xlabel(\"Engine size\")\nplt.ylabel(\"Emission\")\nplt.show()"]},{"cell_type":"code","id":"19059d65-c7e7-4761-b862-57b202997492","metadata":{},"outputs":[],"source":["plt.scatter(X_train[:,1], y_train,  color='blue')\nplt.plot(X_train[:,1], coef_[0,1] * X_train[:,1] + intercept_[0], '-r')\nplt.xlabel(\"FUELCONSUMPTION_COMB_MPG\")\nplt.ylabel(\"Emission\")\nplt.show()"]},{"cell_type":"markdown","id":"6ca9d563-1e9b-4e56-98bc-32fd7af3bb73","metadata":{},"outputs":[],"source":["Evidently, the solution is incredibly poor because the model is trying to fit a plane to a non-planar surface.\n"]},{"cell_type":"markdown","id":"e36a6bf0-0a37-4794-b88a-59e64f0dc1fd","metadata":{},"outputs":[],"source":["### Exercise 1\n","Determine and print the parameters for the best-fit linear regression line for CO2 emission with respect to engine size.\n"]},{"cell_type":"code","id":"ce3d2ab6-80f8-459b-8a52-92e136a65d97","metadata":{},"outputs":[],"source":["X_train_1 = # ADD CODE\n\nregressor_1 = linear_model.LinearRegression()\nregressor_1.# ADD CODE\ncoef_1 =  # ADD CODE\nintercept_1 = # ADD CODE\n\nprint ('Coefficients: ',coef_1)\nprint ('Intercept: ',intercept_1)\n"]},{"cell_type":"markdown","id":"6fd46bb1-ff0f-4117-b625-a80530d8eb89","metadata":{},"outputs":[],"source":["<details><summary>Click here for the solution</summary>\n","\n","```python   \n","\n","X_train_1 = X_train[:,0]\n","regressor_1 = linear_model.LinearRegression()\n","regressor_1.fit(X_train_1.reshape(-1, 1), y_train)\n","coef_1 =  regressor_1.coef_\n","intercept_1 = regressor_1.intercept_\n","print ('Coefficients: ',coef_1)\n","print ('Intercept: ',intercept_1)\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"44e2c240-780b-49ef-a234-e152b8e3d126","metadata":{},"outputs":[],"source":["### Exercise 2\n","Produce a scatterplot of CO2 emission against ENGINESIZE and include the best-fit regression line to the training data.  \n"]},{"cell_type":"code","id":"8a3c529e-2057-4398-8e2d-964537989f87","metadata":{},"outputs":[],"source":["# Enter your code here\nplt.scatter(# ADD CODE, y_train,  color='blue')\nplt.plot(# ADD CODE, coef_1[0] * X_train_1 + intercept_1, '-r')\nplt.xlabel(\"Engine size\")\nplt.ylabel(\"Emission\")"]},{"cell_type":"markdown","id":"85ac5a47-52c8-41a4-89fa-49c56c98ec50","metadata":{},"outputs":[],"source":["<details><summary>Click here for the solution</summary>\n","\n","```python  \n","plt.scatter(X_train_1, y_train,  color='blue')\n","plt.plot(X_train_1, coef_1[0] * X_train_1 + intercept_1, '-r')\n","plt.xlabel(\"Engine size\")\n","plt.ylabel(\"Emission\")\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"1e5ba7a2-50bb-4b16-9092-8e7df461ee86","metadata":{},"outputs":[],"source":["Evidently, this simple linear regression model provides a much better fit of CO2 emissions on the training data than the multiple regression model did. Let's see what its performance is on the test data.\n"]},{"cell_type":"markdown","id":"5651a905-50b2-4c9b-bcd2-244e3a47a613","metadata":{},"outputs":[],"source":["### Exercise 3\n","Generate the same scatterplot and best-fit regression line, but now base the result on the test data set. \n","Consider how the test result compares to the training result.\n"]},{"cell_type":"code","id":"20f5b5fd-07cc-4dfd-9235-f7460fc6d4e7","metadata":{},"outputs":[],"source":["# Enter your code here\nX_test_1 =# ADD CODE[:,0]\nplt.scatter(#ADD CODE, y_test,  color='blue')\nplt.plot(# ADD CODE, coef_1[0] * # ADD CODE + intercept_1, '-r')\nplt.xlabel(\"Engine size\")\nplt.ylabel(\"CO2 Emission\")"]},{"cell_type":"markdown","id":"d3373c29-97aa-44c4-a886-7b3ba59814fe","metadata":{},"outputs":[],"source":["<details><summary>Click here for the solution</summary>\n","\n","```python  \n","\n","X_test_1 = X_test[:,0]\n","plt.scatter(X_test_1, y_test,  color='blue')\n","plt.plot(X_test_1, coef_1[0] * X_test_1 + intercept_1, '-r')\n","plt.xlabel(\"Engine size\")\n","plt.ylabel(\"CO2 Emission\")\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"74b06c5c-d9bf-4675-b427-9f9f1df64798","metadata":{},"outputs":[],"source":["### Exercise 4\n","Repeat the same modeling but use FUELCONSUMPTION_COMB_MPG as the independent variable instead. Display the model coefficients including the intercept.\n"]},{"cell_type":"code","id":"9b4af23b-3e5b-4822-bda1-20f6fb5d8776","metadata":{},"outputs":[],"source":["X_train_2 = # ADD CODE"]},{"cell_type":"markdown","id":"a851065a-bb42-4ad4-b336-7176f83f0958","metadata":{},"outputs":[],"source":["<details><summary>Click here for the solution</summary>\n","\n","```python   \n","X_train_2 = X_train[:,1]\n","regressor_2 = linear_model.LinearRegression()\n","regressor_2.fit(X_train_2.reshape(-1, 1), y_train)\n","coef_2 =  regressor_2.coef_\n","intercept_2 = regressor_2.intercept_\n","print ('Coefficients: ',coef_2)\n","print ('Intercept: ',intercept_2)\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"15b7cf50-217a-4f03-b7a0-6d21e424ee17","metadata":{},"outputs":[],"source":["### Exercise 5\n","Generate a scatter plot showing the results as before on the test data.\n","Consider  well the model fits, and what you might be able to do to improve it. We'll revisit this later in the course.\n"]},{"cell_type":"code","id":"4b11a211-9608-42c0-9847-56a5d7da9f3f","metadata":{},"outputs":[],"source":["# write your code here\nX_test_2 = X_test[:,# ADD CODE]\nplt.scatter(X_test_2, # ADD CODE,  color='blue')\nplt.plot(X_test_2, # ADD CODE, '-r')\nplt.xlabel(\"# ADD CODE\")\nplt.ylabel(\"CO2 Emission\")\n"]},{"cell_type":"markdown","id":"4905be9d-3302-4a1c-ba7e-1414d004d64a","metadata":{},"outputs":[],"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","X_test_2 = X_test[:,1]\n","plt.scatter(X_test_2, y_test,  color='blue')\n","plt.plot(X_test_2, coef_2[0] * X_test_2 + intercept_2, '-r')\n","plt.xlabel(\"combined Fuel Consumption (MPG)\")\n","plt.ylabel(\"CO2 Emission\")\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"d3e42864-8dbf-49f0-9b39-05329e2dd8e1","metadata":{},"outputs":[],"source":["### Congratulations! You're ready to move on to your next lesson!\n","## Author\n","\n","<a href=\"https://www.linkedin.com/in/jpgrossman/\" target=\"_blank\">Jeff Grossman</a>\n","\n","### Other Contributor(s)\n","\n","<a href=\"https://www.linkedin.com/in/abhishek-gagneja-23051987/\" taget=\"_blank\">Abhishek Gagneja</a>\n","\n","<h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n","\n"," \n","<!--\n","## Change Log\n"," \n"," \n","|  Date (YYYY-MM-DD) |  Version       | Changed By     | Change Description                  |\n","|---|---|---|---|\n","| 2024-10-31         | 3.0            | Jeff Grossman  | Rewrite                             |\n","| 2020-11-03         | 2.1            | Lakshmi        | Made changes in URL                 |\n","| 2020-11-03         | 2.1            | Lakshmi        | Made changes in URL                 |\n","| 2020-08-27         | 2.0            | Lavanya        | Moved lab to course repo in GitLab  |\n","|   |   |   |   |\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"faf6774e3618e61ee1e3e9fce47c95dada2b72726d47997cc166152d13094bb0"},"nbformat":4,"nbformat_minor":4}